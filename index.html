<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="From Language To Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance">
  <meta property="og:title" content="From Language To Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance"/>
  <meta property="og:description" content="From Language To Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidanceg"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/teaser.png" />
  <meta property="og:image:width" content="1808"/>
  <meta property="og:image:height" content="1014"/>


  <meta name="twitter:title" content="From Language To Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance">
  <meta name="twitter:description" content="From Language To Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser-1.pdf">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Motion Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>RoboGhost</title>
  
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JHTFKVMFDL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-JHTFKVMFDL');
</script>
  
  <link rel="icon" type="image/x-icon" href="static/images/framework.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://aigc3d.github.io/LaMP/">
            LaMP (ICLR 2025)
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2412.09901">
            MulSMo
          </a>
        </div>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
  
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <!-- 新增img标签用于显示小图标 -->
              <img src="static/images/icon.png" style="width: 64px; height: 64px; vertical-align: middle; margin-right: 8px;">
              From Language To Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance
            </h1>

            
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Zhe Li<sup>1</sup>*,
              </span>
              <span class="author-block">
                Cheng Chi<sup>2</sup>*,
              </span>
              <span class="author-block">
                Yangyang Wei<sup>3</sup>,
              </span>
              <span class="author-block">
                Boan Zhu<sup>4</sup>,
              </span>
              <span class="author-block">
                Yibo Peng<sup>2</sup>,
              </span>
              <span class="author-block">
                Tao Huang<sup>5</sup>,
              </span>
              <span class="author-block">
                Pengwei Wang<sup>2</sup>,
              </span>
              <span class="author-block">
                Zhongyuan Wang<sup>2</sup>,
              </span>
              <span class="author-block">
                Shanghang Zhang<sup>2,6</sup>†
              </span>
              <span class="author-block">
                Chang Xu<sup>1</sup>†
              </span>
              
            </div>
            <div class="is-size-5 publication-authors">
              <span class="eql-cntrb" style="display:block;"><large><sup>1</sup>University of Sydney</large></span>
              <span class="eql-cntrb" style="display:block;"><large><sup>2</sup>BAAI</large></span>
              <span class="eql-cntrb" style="display:block;"><large><sup>3</sup>Harbin Institute of Technology</large></span>
              <span class="eql-cntrb" style="display:block;"><large><sup>4</sup>Hong Kong University of Science and Technology</large></span>
              <span class="eql-cntrb" style="display:block;"><large><sup>5</sup>Shanghai Jiao Tong University</large></span>
              <span class="eql-cntrb" style="display:block;"><large><sup>6</sup>Peking University</large></span>

            <div class="is-size-5 publication-authors">
              <span class="eql-cntrb">* Equal Contribution &nbsp &nbsp † Corresponding Author </span>
            </div>


          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- <img src="static/images/framework.pdf" alt="MY ALT TEXT"/> -->
          <p>
            Language plays a vital role in the realm of human motion. Natural language offers a natural interface for humanoid robots, but existing language-guided humanoid locomotion pipelines remain cumbersome and unreliable. They typically decode human motion, retarget it to robot morphology, and then track it with a physics-based controller. However, this multi-stage process is prone to cumulative errors, introduces high latency, and yields weak coupling between semantics and control. These limitations call for a more direct pathway from language to action, one that eliminates fragile intermediate stages. Therefore, we present RoboGhost, a retargeting-free framework that directly conditions humanoid policies on language-grounded motion latents. By bypassing explicit motion decoding and retargeting, RoboGhost enables a diffusion-based policy to denoise executable actions directly from noise, preserving semantic intent and
supporting fast, reactive control. A hybrid causal transformer–diffusion motion generator further ensures long-horizon consistency while maintaining stability and diversity, yielding rich latent representations for precise humanoid behavior.
Extensive experiments demonstrate that RoboGhost substantially reduces deployment latency, improves success rates and tracking accuracy, and produces smooth, semantically aligned locomotion on real humanoids. Beyond text, the framework
naturally extends to other modalities such as images, audio, and music, providing a general foundation for vision–language–action humanoid systems.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method -->
<section class="section hero">
  <div class="container is-max-desktop">
      <h2 class="title is-3" align="center">Methodology</h2>
      <div class="content has-text-justified">
        <img src="static/images/teaser-1.pdf" width="100%" height="100%" />
        <p>
          RoboGhost is a retargeting-free latent driven policy for language-guided humanoid locomotion. By removing the dependency on motion retargeting, it thus allows robots to be controlled directly via open-ended language commands. The figure showcases (a) the previous pipeline with motion retargeting, (b) our proposed
          retargeting-free latent-driven pipeline, (c) quantitative comparisons of success rate and time cost between
          baseline and RoboGhost, (d) performing the backflip, and (e) dancing and leaping forward.
        </p>
      </div>
      <br>
      <!-- <h2 class="title is-5">LaMP-T2M and LaMP-M2T frameworks overview:</h2> -->
      <div class="content has-text-justified">
        <img src="static/images/framework.png" width="100%" height="100%" />
        <p>
          Overview of RoboGhost. We propose a two-stage approach: a motion latent is first generated, then a MoE-based teacher policy is trained with RL and a diffusion-based student policy is trained to denoise actions conditioned on motion latent. This latent-driven scheme bypasses the need for motion retargeting.
        </p>
      </div>
  </div>
</section>
<!-- End Method -->


<!-- Experiments -->
<section class="section hero">
  <div class="container is-max-desktop">
      <h2 class="title is-3" align="center">Experiments</h2>
      <div class="content has-text-centered">
        <video id="replay-video"
               controls
               muted
               preload
               playsinline
               width="100%">
          <source src="./static/images/video.mp4"
                  type="video/mp4">
        </video>
      </div>
      <h2 class="title is-5">Quantitative Results:</h2>
      <div style="text-align: center; margin: 8px 0;">
        <span style="font-size: 1.1em; font-weight: 500;">Tracking Performance</span>
      </div>

      <div style="text-align: center;">
        <img src="static/images/track-exp.png" width="80%" height="100%"/>
      </div>
      <br>
      <div style="text-align: center; margin: 8px 0;">
        <span style="font-size: 1.1em; font-weight: 500;">Text-to-Motion Performance</span>
      </div>
      <div style="text-align: center;">
        <img src="static/images/t2m-exp.png" width="80%" height="100%"/>
      </div>
      <br>
      <h2 class="title is-5">Qualitative Results:</h2>
      <div style="text-align: center; margin: 8px 0;">
        <span style="font-size: 1.1em; font-weight: 500;">Simulation Performance</span>
      </div>
      <div style="text-align: center;">
        <img src="static/images/sim-1.png" width="80%" height="100%" />
      </div>
      <div style="text-align: center;">
        <img src="static/images/sim-2.png" width="80%" height="100%" />
      </div>
      <div style="text-align: center; margin: 8px 0;">
        <span style="font-size: 1.1em; font-weight: 500;">Real-world Performance</span>
      </div>
      <div style="text-align: center;">
        <img src="static/images/real.png" width="80%" height="100%" />
      </div>
      <div style="text-align: center; margin: 8px 0;">
        <span style="font-size: 1.1em; font-weight: 500;">Generated Motion Visualization</span>
      </div>
      <div style="text-align: center;">
        <img src="static/images/t2m.png" width="80%" height="100%" />
      </div>
  </div>
</section>
<!-- End Method -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
<pre><code>@article{li2025roboghost,
    title={From Language To Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance},
    author={Zhe Li and Chengchi and Yangyang Wei and Boan Zhu and Yibo Peng and Tao Huang and Pengwei Wang and and Zhongyuan Wang and Shanghang Zhang and Chang Xu},
    journal={arXiv preprint arXiv:2510.14952},
    year={2025}
}
    </code></pre>
  </div>
</section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
